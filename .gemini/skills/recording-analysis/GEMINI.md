---
name: recording-analysis
description: [PROTOTYPE] Adaptive video and screen recording analysis pipeline using OmniParser (GPU) or PaddleOCR (CPU). Performs strict environment diagnosis before execution.
---

# Recording Analysis Skill [PROTOTYPE]

**STATUS: PROTOTYPE / EXPERIMENTAL**
This skill is currently in a prototype state. It uses a mock Vision Processor for testing the orchestration pipeline.

Analyze video or screen recordings to extract UI components and textual information using an adaptive pipeline.

## When to Use

Use this skill when:
- The user asks to "analyze this video" or "analyze this screen recording".
- You need to extract text or UI elements from a video file.
- The user provides a video file path for inspection.

## Protocols

### 1. Diagnosis First
**ALWAYS** run the diagnosis script first to determine the available hardware acceleration and software readiness.

```bash
bun .gemini/skills/recording-analysis/scripts/diagnose.ts
```

### 2. Check Diagnosis Result
- If diagnosis returns "NEEDS_SETUP" (exit code 1), display the content of `CUDA_SETUP_GUIDE.md` (generated by the script) to the user and **STOP**.
- If diagnosis is successful (exit code 0), proceed to execution.

### 3. Execution
Run the orchestrator script to process the video.

```bash
bun .gemini/skills/recording-analysis/scripts/orchestrator.ts --input <video-path>
```

## Architecture

1.  **Diagnosis**: Checks for GPU/CUDA/Torch. Generates `env_config.json`.
2.  **Orchestration**: 
    -   Reads config.
    -   **Extracts frames** using FFmpeg (system dependency).
    -   Delegates frame analysis to Vision Processor.
3.  **Vision Processor**: Python-based tool (currently `tools/vision_processor.py`) running OmniParser or PaddleOCR.

## References

- `references/workflow_routing.md`: Logic for backend selection.
- `references/error_handling.md`: Handling OOM and other failures.